{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163cf897",
   "metadata": {},
   "source": [
    "# E-Commerce Sales Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed017b47",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bed9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36a915",
   "metadata": {},
   "source": [
    "#### Loading both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873473c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first CSV file\n",
    "df1 = pd.read_csv('online_retail_I.csv')\n",
    "print(\"Successfully loaded file1\")\n",
    "\n",
    "# Load the second CSV file\n",
    "df2 = pd.read_csv('online_retail_II.csv')\n",
    "print(\"Successfully loaded file2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1271ba9",
   "metadata": {},
   "source": [
    "#### Merging both datasets into one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60379be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7877cf2",
   "metadata": {},
   "source": [
    "#### Saving merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ad924",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('merged_file.csv', index=False)\n",
    "\n",
    "print(\"\\nFiles merged successfully!\")\n",
    "print(\"The merged data is saved in 'merged_file.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Customer ID'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c5a7c",
   "metadata": {},
   "source": [
    "### Basic Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7be51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9630352",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns=merged_df.columns.str.strip()\n",
    "\n",
    "print(\"--- Before Processing ---\")\n",
    "print(merged_df.head())\n",
    "\n",
    "print(f\"\\nTotal missing Customer IDs before: {merged_df['Customer ID'].isnull().sum()}\")\n",
    "\n",
    "# 1. Identify unique invoices that have missing CustomerIDs.\n",
    "invoices_with_missing_ids = merged_df[merged_df['Customer ID'].isnull()]['Invoice'].unique()\n",
    "print(f\"\\nFound {len(invoices_with_missing_ids)} unique invoices that need a new Customer ID.\")\n",
    "\n",
    "# 2. Find the maximum existing CustomerID to ensure new IDs don't conflict.\n",
    "max_existing_id = int(merged_df['Customer ID'].dropna().max())\n",
    "print(f\"Maximum existing Customer ID is: {max_existing_id}. New IDs will start after this number.\")\n",
    "\n",
    "# 3. Create a mapping from each unique invoice to a new, unique CustomerID.\n",
    "start_new_id_from = max_existing_id + 1\n",
    "invoice_to_new_id_map = {\n",
    "    invoice: start_new_id_from + i\n",
    "    for i, invoice in enumerate(invoices_with_missing_ids)\n",
    "}\n",
    "\n",
    "# 4. Fill the missing 'Customer ID' values using the map.\n",
    "merged_df['Customer ID'] = merged_df['Customer ID'].fillna(merged_df['Invoice'].map(invoice_to_new_id_map))\n",
    "\n",
    "# 5. Convert the 'Customer ID' column to an integer type.\n",
    "merged_df['Customer ID'] = merged_df['Customer ID'].astype(int)\n",
    "\n",
    "print(\"\\n--- After Processing ---\")\n",
    "print(merged_df.head())\n",
    "\n",
    "print(f\"\\nTotal missing Customer IDs after: {merged_df['Customer ID'].isnull().sum()}\")\n",
    "\n",
    "merged_df.to_csv('cleaned_01.csv', index=False)\n",
    "print('File Saved Successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0655b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.read_csv('cleaned_01.csv')\n",
    "new_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df=new_df.dropna(subset=['Description'])\n",
    "\n",
    "# Save this new, smaller DataFrame to 'cleaned_02.csv'\n",
    "cleaned_df.to_csv('final_data.csv', index=False)\n",
    "\n",
    "print('Data cleaned and saved as new file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.read_csv('final_data.csv')\n",
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d28452",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Customer ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Invoice'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1825e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f941518",
   "metadata": {},
   "source": [
    "#### Creating new feature 'TotalPrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2816f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['TotalPrice']=(final_df['Quantity']*final_df['Price']).round(2)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34075e4",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb56ae",
   "metadata": {},
   "source": [
    "#### Sales by Hour of the Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c0042",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['InvoiceDate']=pd.to_datetime(final_df['InvoiceDate'], format=\"%d-%m-%Y %H:%M\")\n",
    "\n",
    "# Extract the hour from the InvoiceDate\n",
    "final_df['Hour']=final_df['InvoiceDate'].dt.hour\n",
    "\n",
    "# Group by hour and count the number of transactions (invoices)\n",
    "hourly_sales=final_df.groupby('Hour')['Invoice'].nunique().reset_index()\n",
    "\n",
    "# Create the line plot\n",
    "plt.figure(figsize=(14,7))\n",
    "sns.lineplot(x='Hour',y='Invoice',data=hourly_sales,marker='o',color='indigo')\n",
    "plt.title('Number of Transactions by Hour of the Day',fontsize=16)\n",
    "plt.xlabel('Hour of the Day',fontsize=12)\n",
    "plt.ylabel('Number of Transactions',fontsize=12)\n",
    "plt.xticks(range(0,24))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d7d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_sales=final_df.groupby('Hour')['Invoice'].nunique()\n",
    "hourly_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9dcf3",
   "metadata": {},
   "source": [
    "#### Analysis of Order Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b76588",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df=final_df[final_df['TotalPrice']>0]\n",
    "\n",
    "# Group by invoice to analyze each transaction\n",
    "order_value=sales_df.groupby('Invoice').agg(\n",
    "    OrderValue=('TotalPrice','sum'),\n",
    "    ItemsInOrder=('Quantity','sum')\n",
    "                        ).reset_index()\n",
    "\n",
    "# Calculate and print the Average Order Value \n",
    "avg_order_value=order_value['OrderValue'].mean()\n",
    "print(f\"The Average Order Value for actual sales is: £{avg_order_value:.2f}\")\n",
    "\n",
    "# Plot the distribution of order values\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.histplot(order_value[order_value['OrderValue']<1000]['OrderValue'],bins=100,kde=True,color='teal')\n",
    "plt.title('Distribution of Order Values (Under £1000)',fontsize=16)\n",
    "plt.xlabel('Order Value (£)',fontsize=12)\n",
    "plt.ylabel('Frequency',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eced3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_value=sales_df.groupby('Invoice').agg(\n",
    "    OrderValue=('TotalPrice','sum'),\n",
    "    ItemsInOrder=('Quantity','sum')\n",
    "                        ).reset_index()\n",
    "order_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2dc727",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame=order_value[order_value['OrderValue'] < 1000],\n",
    "    x='OrderValue',\n",
    "    nbins=100,\n",
    "    title='Distribution of Order Values (Under £1000)',\n",
    "    labels={'OrderValue': 'Order Value (£)', 'Invoice Count': 'Frequency'},\n",
    "    color_discrete_sequence=['teal']\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e19d95",
   "metadata": {},
   "source": [
    "#### Relationship Between Price and Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Price']=pd.to_numeric(final_df['Price'],errors='coerce')\n",
    "final_df['Quantity']=pd.to_numeric(final_df['Quantity'],errors='coerce')\n",
    "\n",
    "plot_df=final_df[(final_df['Quantity']>0)&(final_df['Price']>0)].copy()\n",
    "\n",
    "p_99=plot_df['Price'].quantile(0.99)\n",
    "q_99=plot_df['Quantity'].quantile(0.99)\n",
    "plot_df=plot_df[(plot_df['Price']<p_99)&(plot_df['Quantity']<q_99)]\n",
    "\n",
    "fig = px.scatter(\n",
    "    data_frame=plot_df,\n",
    "    x='Price',\n",
    "    y='Quantity',\n",
    "    title='Price vs. Quantity Sold (Interactive)',\n",
    "    labels={'Price':'Price (£)','Quantity':'Quantity Sold'},\n",
    "    opacity=0.5 \n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title_font_size=16,\n",
    "    xaxis_title_font_size=12,\n",
    "    yaxis_title_font_size=12,\n",
    "    plot_bgcolor='white' \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90405885",
   "metadata": {},
   "source": [
    "#### New vs. Returning Customer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['FirstPurchaseDate']=final_df.groupby('Customer ID')['InvoiceDate'].transform('min')\n",
    "\n",
    "final_df['InvoiceMonth']=final_df['InvoiceDate'].dt.to_period('M')\n",
    "final_df['FirstPurchaseMonth']=final_df['FirstPurchaseDate'].dt.to_period('M')\n",
    "\n",
    "final_df['CustomerType']='Returning'\n",
    "final_df.loc[final_df['InvoiceMonth']==final_df['FirstPurchaseMonth'],'CustomerType']='New'\n",
    "\n",
    "cust_trend = final_df.groupby(['InvoiceMonth','CustomerType'])['Customer ID'].nunique().reset_index()\n",
    "cust_trend_pivot = cust_trend.pivot(index='InvoiceMonth',columns='CustomerType',values='Customer ID').fillna(0)\n",
    "\n",
    "cust_trend_pivot.plot(\n",
    "    kind='bar',\n",
    "    stacked=False, \n",
    "    figsize=(14, 8),\n",
    "    colormap='viridis'\n",
    ")\n",
    "\n",
    "plt.title('New vs. Returning Customers Over Time', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Number of Unique Customers', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right') \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc51a56b",
   "metadata": {},
   "source": [
    "#### Country wise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d121fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "country_revenue = final_df.groupby('Country')['TotalPrice'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=country_revenue.values, y=country_revenue.index, \n",
    "            palette='viridis',hue=country_revenue.index,legend=False)\n",
    "\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.title('Top 10 Countries by Total Revenue (Log Scale)', fontsize=16)\n",
    "plt.xlabel('Total Revenue (£) - Log Scale', fontsize=12)\n",
    "plt.ylabel('Country', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15930373",
   "metadata": {},
   "source": [
    "#### Best selling products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by product description and sum the quantity\n",
    "product_quantity = final_df.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=product_quantity.values,y=product_quantity.index, \n",
    "            palette='plasma',hue=product_quantity.index,legend=False)\n",
    "plt.title('Top 10 Best-Selling Products by Quantity', fontsize=16)\n",
    "plt.xlabel('Total Quantity Sold', fontsize=12)\n",
    "plt.ylabel('Product Description', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef09478",
   "metadata": {},
   "source": [
    "#### Seasonal Pattern in Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff721d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'YearMonth' column for grouping\n",
    "final_df['YearMonth']=final_df['InvoiceDate'].dt.to_period('M')\n",
    "monthly_sales=final_df.groupby('YearMonth')['TotalPrice'].sum().reset_index()\n",
    "\n",
    "# Convert 'YearMonth' back to a plottable format\n",
    "monthly_sales['YearMonth']=monthly_sales['YearMonth'].dt.to_timestamp()\n",
    "\n",
    "# Create the line plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.lineplot(x='YearMonth', y='TotalPrice', data=monthly_sales, marker='o')\n",
    "plt.title('Total Sales Revenue Over Time', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Total Revenue (£)', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff051a9e",
   "metadata": {},
   "source": [
    "#### Top 25 Customers by Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Customer ID and sum TotalPrice\n",
    "top_cust=final_df.groupby('Customer ID')['TotalPrice'].sum().sort_values(ascending=False).head(25)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=top_cust.values, y=top_cust.index.astype(str), \n",
    "            palette='viridis', hue=top_cust.index,legend=False)\n",
    "plt.title('Top 25 Custmers by Revenue', fontsize=14)\n",
    "plt.xlabel('Total Revenue (£)', fontsize=10)\n",
    "plt.ylabel('Customer ID', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbefbae",
   "metadata": {},
   "source": [
    "#### Time Between Purchases (Purchase Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1117bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of unique purchase dates for each cust\n",
    "cust_buy=final_df[['Customer ID','InvoiceDate']].drop_duplicates()\n",
    "\n",
    "# Sort by customer and date\n",
    "cust_buy=cust_buy.sort_values(['Customer ID','InvoiceDate'])\n",
    "\n",
    "# Calc the diff btw consecutive purchases for each cust\n",
    "cust_buy['TimeDiff']=cust_buy.groupby('Customer ID')['InvoiceDate'].diff()\n",
    "\n",
    "# Convert the time diff to days\n",
    "cust_buy['DaysDiff']=cust_buy['TimeDiff'].dt.days\n",
    "\n",
    "# Calc and print the average time\n",
    "avg_time=cust_buy['DaysDiff'].mean()\n",
    "print(f\"Average time between customer purchases: {avg_time:.2f} days\")\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.histplot(cust_buy['DaysDiff'].dropna(),bins=50,kde=True, color='red')\n",
    "plt.title('Distribution of Days Between Consecutive Purchases', fontsize=16)\n",
    "plt.xlabel('Days Between Purchases', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlim(0, 200) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799f1fd5",
   "metadata": {},
   "source": [
    "#### Product Portfolio Analysis (ABC Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_rev=final_df.groupby('Description')['TotalPrice'].sum().sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Calculate cumulative revenue and percentage\n",
    "prod_rev['CumulativeRevenue']=prod_rev['TotalPrice'].cumsum()\n",
    "prod_rev['CumulativePercentage']=100 * prod_rev['CumulativeRevenue']/prod_rev['TotalPrice'].sum()\n",
    "\n",
    "# Define ABC categories\n",
    "def categorize_product(percentage):\n",
    "    if percentage <= 80:\n",
    "        return 'Top 80%'\n",
    "    elif 80 < percentage <= 95:\n",
    "        return 'Next 15%'\n",
    "    else:\n",
    "        return 'Bottom 5%'\n",
    "\n",
    "prod_rev['Category']=prod_rev['CumulativePercentage'].apply(categorize_product)\n",
    "\n",
    "# Count the number of products in each category\n",
    "cat_counts = prod_rev['Category'].value_counts().reindex(['Top 80%','Next 15%','Bottom 5%'])\n",
    "print(\"Product Count by Category:\")\n",
    "print(cat_counts)\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=cat_counts.index, y=cat_counts.values, \n",
    "            palette='YlGnBu',hue=cat_counts.index,legend=False)\n",
    "plt.title('Product Category based on Revenue', fontsize=16)\n",
    "plt.xlabel('Product Category', fontsize=12)\n",
    "plt.ylabel('Count of Products', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77dd14",
   "metadata": {},
   "source": [
    "#### Geographic Analysis (Beyond the UK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9686d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate UK from the rest of the world\n",
    "uk_df=final_df[final_df['Country']=='United Kingdom']\n",
    "non_uk_df=final_df[final_df['Country']!='United Kingdom']\n",
    "\n",
    "# Plot top 10 non-UK countries by revenue\n",
    "top_non_uk=non_uk_df.groupby('Country')['TotalPrice'].sum().sort_values(ascending=False).head(10)\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x=top_non_uk.values, y=top_non_uk.index, \n",
    "            palette='cividis',hue=top_non_uk.index,legend=False)\n",
    "plt.title('Top 10 Non-UK Countries by Revenue',fontsize=16)\n",
    "plt.xlabel('Total Revenue (£)',fontsize=12)\n",
    "plt.ylabel('Country',fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Compare Average Order Value (AOV)\n",
    "uk_aov=uk_df.groupby('Invoice')['TotalPrice'].sum().mean()\n",
    "non_uk_aov=non_uk_df.groupby('Invoice')['TotalPrice'].sum().mean()\n",
    "\n",
    "print(f\"Average Order Value (UK): £{uk_aov:.2f}\")\n",
    "print(f\"Average Order Value (Others): £{non_uk_aov:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7140d46a",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "- Business Core: The business is heavily reliant on the domestic UK market, which accounts for the vast majority of revenue. The top international markets are Netherlands, EIRE, Germany, and France.\n",
    "\n",
    "- Sales Cycle: Sales are highly seasonal, with a significant peak in October and November leading into the holidays. The busiest time of day is between 10 AM and 3 PM.\n",
    "\n",
    "- Customer Profile: The customer base consists of a growing number of returning customers, and a small number of VIP customers are responsible for a large portion of revenue. The average order value is approximately £523.30.\n",
    "\n",
    "- Product Catalog: The business model is driven by high-volume sales of low-price items, with most products costing less than £5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ff4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all the work\n",
    "final_df.to_csv('analytics_ready_data.csv', index=False)\n",
    "print(\"Final DataFrame is saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c9e3f",
   "metadata": {},
   "source": [
    "## RFM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd07b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('analytics_ready_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae41e83",
   "metadata": {},
   "source": [
    "#### Calculating RFM Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# To calculate Recency, we need a \"snapshot\" date. This will be the day after the last transaction.\n",
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
    "snapshot_date=data['InvoiceDate'].max()+dt.timedelta(days=1)\n",
    "\n",
    "# Group by each customer and calculate RFM values\n",
    "rfm_df=data.groupby('Customer ID').agg({\n",
    "    'InvoiceDate': lambda date: (snapshot_date - date.max()).days, # Recency\n",
    "    'Invoice': 'nunique',                                          # Frequency\n",
    "    'TotalPrice': 'sum'                                            # Monetary\n",
    "})\n",
    "\n",
    "# Rename the columns to be more descriptive\n",
    "rfm_df.rename(columns={'InvoiceDate': 'Recency',\n",
    "                       'Invoice': 'Frequency',\n",
    "                       'TotalPrice': 'MonetaryValue'}, inplace=True)\n",
    "\n",
    "print(\"\\nRFM Metrics Calculated:\")\n",
    "print(rfm_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f89a32d",
   "metadata": {},
   "source": [
    "#### Creating RFM Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc253033",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_labels=range(5, 0, -1) # 5 is best (most recent), 1 is worst\n",
    "f_labels=range(1, 6)     # 5 is best (most frequent), 1 is worst\n",
    "m_labels=range(1, 6)     # 5 is best (highest value), 1 is worst\n",
    "\n",
    "# The .rank(method='first') ensures each value gets a unique rank, which qcut can divide perfectly.\n",
    "rfm_df['R_Score']=pd.qcut(rfm_df['Recency'].rank(method='first'),q=5,labels=r_labels)\n",
    "rfm_df['F_Score']=pd.qcut(rfm_df['Frequency'].rank(method='first'),q=5,labels=f_labels)\n",
    "rfm_df['M_Score']=pd.qcut(rfm_df['MonetaryValue'].rank(method='first'),q=5, labels=m_labels)\n",
    "\n",
    "print(\"\\nRFM Scores Created:\")\n",
    "print(rfm_df[['Recency','R_Score','Frequency','F_Score','MonetaryValue','M_Score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbc365",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1154f68",
   "metadata": {},
   "source": [
    "#### Defining RFM Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2dae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df['RFM_Segment_Score']=rfm_df.apply(lambda row: str(row['R_Score'])+str(row['F_Score'])+str(row['M_Score']),axis=1)\n",
    "\n",
    "rfm_df['RFM_Score']=rfm_df[['R_Score','F_Score','M_Score']].sum(axis=1)\n",
    "\n",
    "# Mapping RFM scores to segment names\n",
    "def assign_segment(score):\n",
    "    if score >= 14:\n",
    "        return 'Champions'\n",
    "    elif score >= 11:\n",
    "        return 'Loyal Customers'\n",
    "    elif score >= 8:\n",
    "        return 'Potential Loyalists'\n",
    "    elif score >= 6:\n",
    "        return 'At-Risk Customers'\n",
    "    elif score >= 4:\n",
    "        return 'Needs Attention'\n",
    "    else:\n",
    "        return 'Lost'\n",
    "    \n",
    "rfm_df['Segment']=rfm_df['RFM_Score'].apply(assign_segment)\n",
    "\n",
    "print(\"\\nCustomer Segments Assigned:\")\n",
    "print(rfm_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7577bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8803ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df['Segment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06511ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df.to_csv('rfm_segmented_customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f8135",
   "metadata": {},
   "source": [
    "#### Top 10 products from each Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91741a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_segments=pd.merge(final_df, rfm_df, on='Customer ID')\n",
    "def get_top_products_for_segment(segment_name,n=10):\n",
    "    \"\"\"\n",
    "    Returns the top N products for a given customer segment.\n",
    "    \"\"\"\n",
    "    segment_df=df_with_segments[df_with_segments['Segment']==segment_name]\n",
    "    top_products=segment_df['Description'].value_counts().head(n)\n",
    "    return top_products\n",
    "\n",
    "# Best customers\n",
    "print(\"--- Top 10 Products for 'Champions' ---\")\n",
    "print(get_top_products_for_segment('Champions'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- Top 10 Products for 'Loyal Customers' ---\")\n",
    "print(get_top_products_for_segment('Loyal Customers'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- Top 10 Products for 'Potential Loyalists' ---\")\n",
    "print(get_top_products_for_segment('Potential Loyalists'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "# Customers we might be about to lose\n",
    "print(\"--- Top 10 Products for 'At-Risk Customers' ---\")\n",
    "print(get_top_products_for_segment('At-Risk Customers'))\n",
    "\n",
    "# Customers we had lost\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- Top 10 Products for 'Lost' ---\")\n",
    "print(get_top_products_for_segment('Lost'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8532d9",
   "metadata": {},
   "source": [
    "#### Top 10 Customers from each Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_segments=pd.merge(final_df, rfm_df, on='Customer ID')\n",
    "def get_top_cust_for_segment(segment_name,n=10):\n",
    "    \"\"\"\n",
    "    Returns the top N products for a given customer segment.\n",
    "    \"\"\"\n",
    "    segment_df=df_with_segments[df_with_segments['Segment']==segment_name]\n",
    "    top_products=segment_df['Customer ID'].value_counts().head(n)\n",
    "    return top_products\n",
    "\n",
    "# Best customers\n",
    "print(\"--- Top 10 Customer for 'Champions' ---\")\n",
    "print(get_top_cust_for_segment('Champions'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- Top 10 Customer for 'Loyal Customers' ---\")\n",
    "print(get_top_cust_for_segment('Loyal Customers'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- Top 10 Customer for 'Potential Loyalists' ---\")\n",
    "print(get_top_cust_for_segment('Potential Loyalists'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "# Customers we might be about to lose\n",
    "print(\"--- Top 10 Customer for 'At-Risk Customers' ---\")\n",
    "print(get_top_cust_for_segment('At-Risk Customers'))\n",
    "\n",
    "# Customers we had lost\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- Top 10 Customer for 'Lost' ---\")\n",
    "print(get_top_cust_for_segment('Lost'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c68447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0e47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
